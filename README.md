# Explainable AI - Neural Reasoning Engine

An interactive web application that visualizes the reasoning process of Large Language Models (LLMs) using 3D force-directed graphs. This project provides transparency into how AI models arrive at their conclusions by exposing the logical steps, assumptions, and dependencies in their decision-making process.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![React](https://img.shields.io/badge/react-19.2.0-61dafb.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-latest-009688.svg)

## üåü Features

- **3D Interactive Visualization**: Explore AI reasoning paths through an immersive 3D force-directed graph
- **Real-time Reasoning Analysis**: Submit queries and watch the AI's thought process unfold
- **Node Type Classification**: Understand different reasoning steps (assumptions, inferences, calculations, decisions, conclusions)
- **Relationship Mapping**: Visualize dependencies between logical steps with directed edges
- **Confidence Tracking**: View assumptions and confidence notes for each response
- **Modern UI**: Sleek, dark-themed interface with smooth animations and responsive design

## üèóÔ∏è Architecture

### Backend (FastAPI + Google Gemini AI)
- **FastAPI** server handling API requests
- **Google Gemini 2.5 Flash** for AI reasoning generation
- Structured JSON responses with reasoning graphs
- CORS-enabled for cross-origin requests

### Frontend (React + Vite)
- **React 19** with modern hooks and state management
- **Zustand** for lightweight state management
- **React Force Graph 3D** for graph visualization
- **Three.js** for 3D rendering
- **TailwindCSS** for styling
- **Axios** for API communication

## üìã Prerequisites

- **Python** 3.8 or higher
- **Node.js** 16 or higher
- **npm** or **yarn**
- **Google Gemini API Key** ([Get it here](https://ai.google.dev/))

## üöÄ Getting Started

### 1. Clone the Repository

```bash
git clone <repository-url>
cd ExplainableAI
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Linux/Mac:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file and add your Google Gemini API key
echo "GOOGLE_API_KEY=your_api_key_here" > .env
```

### 3. Frontend Setup

```bash
cd ../frontend

# Install dependencies
npm install

# Create .env file for local development
cp .env.example .env

# The .env file should contain:
# VITE_API_BASE_URL=http://localhost:8000
```

### 4. Running the Application

#### Start the Backend Server

```bash
cd backend
source venv/bin/activate  # If not already activated
uvicorn main:app --reload --port 8000
```

The backend API will be available at `http://localhost:8000`

#### Start the Frontend Development Server

```bash
cd frontend
npm run dev
```

The frontend will be available at `http://localhost:5173` (or another port if 5173 is occupied)

## üéØ Usage

1. Open your browser and navigate to the frontend URL (typically `http://localhost:5173`)
2. Enter a question or problem in the chat input at the bottom of the screen
3. Press Enter or click Submit
4. Watch as the AI generates a reasoning graph showing its thought process
5. Click on nodes to view detailed information about each reasoning step
6. Explore the 3D graph by:
   - **Dragging**: Rotate the camera view
   - **Scrolling**: Zoom in/out
   - **Clicking nodes**: View detailed information

## üìä Response Structure

The AI returns structured responses with the following format:

```json
{
  "final_answer": "The conclusion or answer to your query",
  "reasoning_graph": {
    "nodes": [
      {
        "id": "S1",
        "title": "Step title",
        "description": "Detailed description",
        "type": "assumption | inference | calculation | decision | conclusion"
      }
    ],
    "edges": [
      {
        "from": "S1",
        "to": "S2",
        "relation": "depends_on | leads_to | supports | verifies"
      }
    ],
    "adjacency_matrix": {
      "node_order": ["S1", "S2", "S3"],
      "matrix": [[0, 1, 0], [0, 0, 1], [0, 0, 0]]
    }
  },
  "assumptions": ["List of assumptions made"],
  "confidence_notes": "Notes about confidence levels"
}
```

## üé® Node Types

The visualization uses different colors to represent different types of reasoning steps:

- üî¥ **Assumption** - Initial premises or given information
- üîµ **Inference** - Logical deductions from other steps
- üü° **Calculation** - Mathematical or computational operations
- üü£ **Decision** - Choice points in the reasoning process
- üü¢ **Conclusion** - Final results or answers

## üõ†Ô∏è Tech Stack

### Backend
- **FastAPI** - Modern, fast web framework for building APIs
- **Google Gemini AI** - Advanced language model for reasoning
- **Python-dotenv** - Environment variable management
- **Pydantic** - Data validation using Python type annotations

### Frontend
- **React 19** - UI library
- **Vite** - Next-generation frontend tooling with environment variable support
- **TailwindCSS 4** - Utility-first CSS framework
- **Zustand** - State management
- **React Force Graph 3D** - 3D graph visualization
- **Three.js** - 3D graphics library
- **Axios** - HTTP client
- **React Hot Toast** - Toast notifications

## üìÅ Project Structure

```
ExplainableAI/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GeminiRequest.py    # Request data models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GeminiResponse.py   # Response data models
‚îÇ   ‚îú‚îÄ‚îÄ Routers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai.py               # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GeminiService.py    # AI service logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GeminiProvider.py   # Dependency injection
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # FastAPI application entry point
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Components/         # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/             # Configuration files
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js          # API endpoint configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ store/              # Zustand state management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx             # Main app component
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx            # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ .env                    # Development environment variables
‚îÇ   ‚îú‚îÄ‚îÄ .env.production         # Production environment variables
‚îÇ   ‚îú‚îÄ‚îÄ .env.example            # Environment variables template
‚îÇ   ‚îú‚îÄ‚îÄ package.json            # Node dependencies
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js          # Vite configuration
‚îî‚îÄ‚îÄ README.md
```

## üîß Configuration

### Backend Configuration

Create a `.env` file in the `backend` directory:

```env
GOOGLE_API_KEY=your_google_gemini_api_key
```

### Frontend Configuration

The frontend uses environment variables to configure the API endpoint. Create a `.env` file in the `frontend` directory:

**For Development:**
```env
VITE_API_BASE_URL=http://localhost:8000
```

**For Production:**
```env
VITE_API_BASE_URL=https://your-backend-url.com
```

The production environment variable is configured in `.env.production` and will be automatically used when you run `npm run build`.

**Note:** Environment variables in Vite must be prefixed with `VITE_` to be exposed to the client-side code.

## üö¢ Deployment

### Building for Production

#### Backend Deployment

The backend can be deployed to any platform that supports Python applications (Heroku, Render, Railway, etc.):

```bash
cd backend

# Make sure all dependencies are in requirements.txt
pip freeze > requirements.txt

# Set environment variables on your hosting platform:
# GOOGLE_API_KEY=your_api_key_here
```

Most platforms will automatically detect the FastAPI application. You may need to specify:
- **Start command**: `uvicorn main:app --host 0.0.0.0 --port $PORT`
- **Python version**: 3.8+

#### Frontend Deployment

1. **Update Production API URL**

   Edit `frontend/.env.production`:
   ```env
   VITE_API_BASE_URL=https://your-backend-url.com
   ```

2. **Build the Frontend**

   ```bash
   cd frontend
   npm run build
   ```

   This creates an optimized production build in the `dist` directory.

3. **Deploy to Static Hosting**

   The built files can be deployed to:
   - **Vercel**: `vercel deploy`
   - **Netlify**: Drag and drop the `dist` folder or use Netlify CLI
   - **GitHub Pages**: Push the `dist` folder to a `gh-pages` branch
   - **Render**: Connect your repository and set build command to `npm run build`

### Environment Variables Summary

| Variable | Location | Purpose | Example |
|----------|----------|---------|---------|
| `GOOGLE_API_KEY` | Backend `.env` | Google Gemini API authentication | `AIza...` |
| `VITE_API_BASE_URL` | Frontend `.env` | Backend API endpoint (development) | `http://localhost:8000` |
| `VITE_API_BASE_URL` | Frontend `.env.production` | Backend API endpoint (production) | `https://api.example.com` |

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- Google Gemini AI for providing the reasoning capabilities
- The React Force Graph community for the amazing visualization library
- FastAPI for the excellent web framework

## üìß Contact

For questions or feedback, please open an issue on the GitHub repository.

---

**Note**: This project requires a Google Gemini API key to function. Make sure to obtain one from [Google AI Studio](https://ai.google.dev/) and add it to your `.env` file before running the application.